"""
AI Proposal generation endpoints.

Includes PDF generation and AI transparency features (Oct 2025).
"""

from uuid import UUID
from fastapi import APIRouter, BackgroundTasks, Depends, HTTPException, status, Request
from fastapi.responses import Response, StreamingResponse
import logging
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from typing import Dict, Any
import io

from app.core.database import get_async_db
from app.api.dependencies import CurrentUser
from app.models.project import Project
from app.schemas.proposal import (
    ProposalGenerationRequest,
    ProposalJobStatus,
    ProposalResponse,
    AIMetadataResponse,
)
from app.schemas.common import ErrorResponse
from app.services.proposal_service import ProposalService
from app.visualization.pdf_generator import pdf_generator
from app.services.s3_service import get_presigned_url, USE_S3

logger = logging.getLogger(__name__)

router = APIRouter()

# Import rate limiter from main app
from app.main import limiter


@router.post(
    "/generate",
    response_model=ProposalJobStatus,
    status_code=status.HTTP_202_ACCEPTED,
    summary="Generate AI proposal",
    description="Start an async job to generate a proposal using AI",
    responses={404: {"model": ErrorResponse}},
)
@limiter.limit("3/minute")  # ‚≠ê Rate limit: AI generation (expensive operation)
async def generate_proposal(
    request: Request,  # Required for rate limiter
    proposal_request: ProposalGenerationRequest,
    background_tasks: BackgroundTasks,
    current_user: CurrentUser,
    db: AsyncSession = Depends(get_async_db),
):
    """
    Start AI-powered proposal generation for a project.

    **This is an async operation.** The endpoint returns immediately with a job ID.
    Use the job ID to poll for status and results.

    **Workflow:**
    1. Request submitted ‚Üí Returns `job_id` with status "queued"
    2. Background worker processes request
    3. AI generates comprehensive proposal (1-2 minutes)
    4. Proposal saved to database
    5. Job status becomes "completed" with proposal ID

    **Polling:**
    - Poll `GET /ai/proposals/jobs/{jobId}` every 2-3 seconds
    - Monitor `progress` (0-100) and `current_step`
    - When status="completed", retrieve `result.proposal_id`

    **Requirements:**
    - Project must exist and belong to current user
    - Project should have technical data filled

    **Parameters:**
    - **project_id**: UUID of the project
    - **proposal_type**: "Conceptual", "Technical", or "Detailed"
    - **preferences**: Optional preferences (focus_areas, constraints)

    **Returns:**
    - **job_id**: Unique identifier for tracking this generation job
    - **status**: "queued" (initial state)
    - **estimated_time**: Estimated completion time in seconds
    """
    # Verify project exists and belongs to user
    result = await db.execute(
        select(Project).where(
            Project.id == proposal_request.project_id,
            Project.user_id == current_user.id,
        )
    )
    project = result.scalar_one_or_none()

    if not project:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Project not found",
        )

    # Start proposal generation
    job_id = await ProposalService.start_proposal_generation(
        db=db,
        project_id=proposal_request.project_id,
        request=proposal_request,
        user_id=current_user.id,
    )

    # Add background task for processing
    # Note: In production, this should be handled by Celery or similar
    # IMPORTANT: Don't pass db session - background task will create its own
    background_tasks.add_task(
        ProposalService.generate_proposal_async_wrapper,
        project_id=proposal_request.project_id,
        request=proposal_request,
        job_id=job_id,
        user_id=current_user.id,
    )

    logger.info(f"üöÄ Proposal generation started: {job_id} for project {proposal_request.project_id}")

    return ProposalJobStatus(
        job_id=job_id,
        status="queued",
        progress=0,
        current_step="Initializing proposal generation...",
        result=None,
        error=None,
    )


@router.get(
    "/jobs/{job_id}",
    response_model=ProposalJobStatus,
    responses={404: {"model": ErrorResponse}},
    summary="Get proposal generation job status",
)
# Rate limiting removed: This endpoint is polled frequently (every 2.5s)
# and already protected by authentication (CurrentUser)
async def get_job_status(
    job_id: str,
    current_user: CurrentUser,
):
    """
    Get the current status of a proposal generation job.
    
    **Poll this endpoint** every 2-3 seconds after submitting a generation request.
    
    **Status values:**
    - **queued**: Job is waiting to be processed
    - **processing**: AI is generating the proposal
    - **completed**: Proposal is ready (check `result` for proposal_id)
    - **failed**: Generation failed (check `error` for details)
    
    **Progress tracking:**
    - `progress`: 0-100 percentage
    - `current_step`: Human-readable description of current operation
    
    **When completed:**
    - `result.proposal_id`: UUID of the generated proposal
    - `result.preview`: Quick preview with summary, costs, technologies
    
    **Example usage:**
    ```javascript
    // Poll every 2 seconds
    const checkStatus = async (jobId) => {
      const response = await fetch(`/api/v1/ai/proposals/jobs/${jobId}`);
      const data = await response.json();
      
      if (data.status === 'completed') {
        // Navigate to proposal
        navigate(`/projects/${projectId}/proposals/${data.result.proposal_id}`);
      } else if (data.status === 'failed') {
        // Show error
        showError(data.error);
      } else {
        // Show progress
        updateProgressBar(data.progress);
        showMessage(data.current_step);
        // Poll again
        setTimeout(() => checkStatus(jobId), 2000);
      }
    };
    ```
    """
    status_data = await ProposalService.get_job_status(job_id)
    
    if not status_data:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Job not found or expired",
        )
    
    return ProposalJobStatus(**status_data)


@router.get(
    "/{project_id}/proposals",
    response_model=list[ProposalResponse],
    responses={404: {"model": ErrorResponse}},
    summary="List project proposals",
)
async def list_proposals(
    project_id: UUID,
    current_user: CurrentUser,
    db: AsyncSession = Depends(get_async_db),
):
    """
    Get all proposals for a project.
    
    Returns proposals ordered by creation date (newest first).
    Each proposal includes version, costs, and status.
    """
    # Verify project access
    result = await db.execute(
        select(Project).where(
            Project.id == project_id,
            Project.user_id == current_user.id,
        )
    )
    project = result.scalar_one_or_none()
    
    if not project:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Project not found",
        )
    
    # Get proposals (relationship already loaded via selectin)
    proposals = project.proposals

    # ‚úÖ Convert to response models with snapshot using helper method
    response_list = [ProposalResponse.from_model_with_snapshot(p) for p in proposals]

    return response_list


@router.get(
    "/{project_id}/proposals/{proposal_id}",
    response_model=ProposalResponse,
    responses={404: {"model": ErrorResponse}},
    summary="Get proposal detail",
)
async def get_proposal(
    project_id: UUID,
    proposal_id: UUID,
    current_user: CurrentUser,
    db: AsyncSession = Depends(get_async_db),
):
    """
    Get detailed proposal information.
    
    Includes full markdown content, equipment specs, costs, and efficiency data.
    """
    # Verify project access
    result = await db.execute(
        select(Project).where(
            Project.id == project_id,
            Project.user_id == current_user.id,
        )
    )
    project = result.scalar_one_or_none()
    
    if not project:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Project not found",
        )
    
    # Find proposal
    from app.models.proposal import Proposal
    result = await db.execute(
        select(Proposal).where(
            Proposal.id == proposal_id,
            Proposal.project_id == project_id,
        )
    )
    proposal = result.scalar_one_or_none()
    
    if not proposal:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Proposal not found",
        )
    
    # ‚úÖ Build response with snapshot using helper method
    return ProposalResponse.from_model_with_snapshot(proposal)


@router.get(
    "/{project_id}/proposals/{proposal_id}/pdf",
    summary="Generate or retrieve a proposal PDF",
    response_class=Response,
    responses={
        200: {"content": {"application/pdf": {}}},
        302: {"description": "Redirect to PDF file"},
        404: {"model": ErrorResponse, "description": "Proposal not found"},
        500: {"model": ErrorResponse, "description": "PDF generation failed"},
        429: {"model": ErrorResponse, "description": "Too many requests"},
    },
)
@limiter.limit("20/minute")  # ‚≠ê Rate limit: PDF generation (moderate - uses cache)
async def get_proposal_pdf(
    request: Request,  # Required for rate limiter
    project_id: UUID,
    proposal_id: UUID,
    current_user: CurrentUser,  # CurrentUser already has Depends in type
    db: AsyncSession = Depends(get_async_db),
    regenerate: bool = False,
):
    """
    Generate and download proposal as professional PDF.
    
    **On-demand generation with caching:**
    - First request: Generates PDF and saves to storage (S3 or local)
    - Subsequent requests: Serves cached PDF from storage
    - Use `?regenerate=true` to force regeneration
    
    **PDF Features:**
    - Professional cover page with branding
    - Financial summary with charts
    - Equipment specifications with justifications
    - Treatment efficiency tables
    - Operational data and costs
    - Implementation timeline
    
    **Storage:**
    - **Production**: S3 with presigned URLs (24h expiry)
    - **Development**: Local filesystem
    
    **Parameters:**
    - **regenerate**: Force PDF regeneration (default: false)
    
    **Returns:**
    - PDF file as `application/pdf`
    - Filename: `Proposal_{version}_{project_name}.pdf`
    """
    # Verify project access
    result = await db.execute(
        select(Project).where(
            Project.id == project_id,
            Project.user_id == current_user.id,
        )
    )
    project = result.scalar_one_or_none()
    
    if not project:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Project not found",
        )
    
    # Get proposal with relationships
    from app.models.proposal import Proposal
    result = await db.execute(
        select(Proposal).where(
            Proposal.id == proposal_id,
            Proposal.project_id == project_id,
        )
    )
    proposal = result.scalar_one_or_none()
    
    if not proposal:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Proposal not found",
        )
    
    # Load project relationship if not loaded
    if not proposal.project:
        proposal.project = project
    
    try:
        # Check if PDF exists and regeneration not requested
        if proposal.pdf_path and not regenerate:
            logger.info(f"üìÑ Serving cached PDF for proposal {proposal_id}")
            
            # Generate fresh presigned URL or serve local path
            pdf_url = await get_presigned_url(proposal.pdf_path, expires=3600)
            
            if pdf_url:
                # Redirect to presigned URL (S3) or local URL
                from fastapi.responses import RedirectResponse
                return RedirectResponse(
                    url=pdf_url,
                    status_code=302  # Temporary redirect
                )
        
        # Generate new PDF using existing ProfessionalPDFGenerator
        logger.info(f"üîÑ Generating new PDF for proposal {proposal_id}")
        
        # Prepare metadata for PDF generator (matches existing interface)
        metadata = {
            "data_for_charts": proposal.technical_data if hasattr(proposal, 'technical_data') else {
                "client_info": {
                    "company_name": project.client,
                    "industry": project.sector,
                    "location": project.location,
                },
                "flow_rate_m3_day": 0,  # Extract from proposal data
                "capex_usd": proposal.capex,
                "annual_opex_usd": proposal.opex,
                "main_equipment": proposal.equipment_list or [],
                "treatment_efficiency": proposal.treatment_efficiency or {},
                "capex_breakdown": proposal.cost_breakdown or {},
                "opex_breakdown": proposal.operational_costs or {},
                "problem_analysis": {},
                "alternative_analysis": [],
                "implementation_months": 12,
            }
        }
        
        # ‚úÖ Generate charts BEFORE creating PDF (like backend-chatbot)
        from app.visualization.modern_charts import premium_chart_generator
        
        logger.info(f"üìä Generating executive charts for proposal {proposal_id}")
        charts = premium_chart_generator.generate_executive_charts(metadata)
        logger.info(f"üìä Generated {len(charts)} charts: {list(charts.keys()) if charts else 'none'}")
        
        # ‚úÖ Generate PDF with charts (returns RELATIVE filename: "proposals/file.pdf")
        pdf_filename = await pdf_generator.create_pdf(
            markdown_content=proposal.technical_approach or "",
            metadata=metadata,
            charts=charts,  # ‚úÖ Now with actual charts
            conversation_id=str(proposal_id)
        )

        if not pdf_filename:
            raise ValueError("PDF generation returned None")

        # ‚úÖ Save RELATIVE filename in database (NOT the full URL)
        proposal.pdf_path = pdf_filename
        await db.commit()

        logger.info(f"‚úÖ PDF generated and saved: {pdf_filename}")

        # ‚úÖ Generate download URL from relative filename
        # In local mode: returns "/uploads/proposals/file.pdf"
        # In S3 mode: returns presigned S3 URL
        pdf_url = await get_presigned_url(pdf_filename, expires=3600)

        if not pdf_url:
            raise ValueError("Failed to generate download URL")

        from fastapi.responses import RedirectResponse
        return RedirectResponse(
            url=pdf_url,
            status_code=302
        )
        
    except Exception as e:
        logger.error(f"‚ùå PDF generation failed: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to generate PDF: {str(e)}",
        )


@router.delete(
    "/{project_id}/proposals/{proposal_id}",
    status_code=status.HTTP_204_NO_CONTENT,
    responses={
        204: {"description": "Proposal deleted successfully"},
        404: {"model": ErrorResponse, "description": "Proposal not found"},
        403: {"model": ErrorResponse, "description": "Not authorized to delete this proposal"},
        429: {"model": ErrorResponse, "description": "Too many requests"},
    },
    summary="Delete a proposal",
    description="Permanently delete a proposal and its associated PDF file. Only the project owner can delete proposals.",
)
@limiter.limit("10/minute")  # ‚≠ê Rate limit: Delete operation (conservative)
async def delete_proposal(
    request: Request,  # Required for rate limiter
    project_id: UUID,
    proposal_id: UUID,
    current_user: CurrentUser,
    db: AsyncSession = Depends(get_async_db),
):
    """
    Delete a proposal permanently.

    **Security:**
    - Only the project owner can delete proposals
    - Cascading delete removes all associated data
    - PDF files are deleted from storage (S3 or local)

    **Best Practices (October 2025):**
    - Returns 204 No Content on success (RESTful standard)
    - Returns 404 if proposal doesn't exist (prevents info leakage)
    - Atomic operation (DB + file deletion)
    """
    # Verify project access and ownership
    result = await db.execute(
        select(Project).where(
            Project.id == project_id,
            Project.user_id == current_user.id,
        )
    )
    project = result.scalar_one_or_none()

    if not project:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Project not found",
        )

    # Get proposal
    from app.models.proposal import Proposal
    result = await db.execute(
        select(Proposal).where(
            Proposal.id == proposal_id,
            Proposal.project_id == project_id,
        )
    )
    proposal = result.scalar_one_or_none()

    if not proposal:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Proposal not found",
        )

    # Store pdf_path before deleting (for cleanup)
    pdf_path = proposal.pdf_path

    # Delete from database (SQLAlchemy will handle cascade)
    await db.delete(proposal)
    await db.commit()

    # Delete PDF file from storage (best effort - don't fail if file doesn't exist)
    if pdf_path:
        try:
            from app.services.s3_service import USE_S3, LOCAL_UPLOADS_DIR
            import os

            if USE_S3:
                # TODO: Implement S3 deletion when S3 is configured
                logger.info(f"üìÑ Would delete from S3: {pdf_path}")
            else:
                # Delete local file
                local_file_path = os.path.join(LOCAL_UPLOADS_DIR, pdf_path)
                if os.path.exists(local_file_path):
                    os.remove(local_file_path)
                    logger.info(f"üóëÔ∏è Deleted local PDF: {local_file_path}")
        except Exception as e:
            # Log error but don't fail the request (file might already be deleted)
            logger.warning(f"Failed to delete PDF file {pdf_path}: {e}")

    logger.info(f"üóëÔ∏è Deleted proposal {proposal_id} from project {project_id}")

    # Return 204 No Content (RESTful standard for successful DELETE)
    return Response(status_code=status.HTTP_204_NO_CONTENT)


@router.get(
    "/{project_id}/proposals/{proposal_id}/ai-metadata",
    response_model=AIMetadataResponse,
    responses={
        200: {"model": AIMetadataResponse},
        404: {"model": ErrorResponse, "description": "Proposal not found"},
        422: {"model": ErrorResponse, "description": "Invalid metadata format"},
        429: {"model": ErrorResponse, "description": "Too many requests"},
    },
    summary="Get AI reasoning and transparency data",
    description="Retrieve validated AI metadata including proven cases, assumptions, and confidence level",
)
@limiter.limit("60/minute")  # ‚≠ê Rate limit: Read operation (permissive)
async def get_proposal_ai_metadata(
    request: Request,  # Required for rate limiter
    project_id: UUID,
    proposal_id: UUID,
    current_user: CurrentUser,
    db: AsyncSession = Depends(get_async_db),
):
    """
    Get AI reasoning and transparency metadata for a proposal.
    
    **Transparency Features (Engineering Co-Pilot):**
    This endpoint exposes the "why" behind the AI's decisions, enabling
    engineers to validate, trust, and improve the proposal.
    
    **Data Included:**
    - **usage_stats**: Token usage, model info, generation time
    - **proven_cases**: Similar projects consulted during generation
    - **assumptions**: Design assumptions made by the AI
    - **alternatives**: Technologies considered but rejected
    - **technology_justification**: Detailed reasoning for selections
    - **confidence_level**: AI's confidence ("High", "Medium", "Low")
    - **recommendations**: Additional recommendations from AI
    
    **Use Cases:**
    1. **Validation Tab**: Show proven cases and deviations in UI
    2. **Q&A Context**: Use for contextual chat with proposal
    3. **Audit Trail**: Document AI decision-making process
    4. **Learning**: Understand AI reasoning to improve inputs
    
    **Example Response:**
    ```json
    {
      "usage_stats": {
        "total_tokens": 45000,
        "model_used": "gpt-4o-mini",
        "success": true
      },
      "proven_cases": [
        {
          "sector": "Food & Beverage",
          "treatment_train": "DAF + UASB + UV",
          "capex_usd": 180000,
          "flow_rate_m3_day": 350
        }
      ],
      "assumptions": [
        "COD/BOD ratio of 2.5 based on F&B industry standards",
        "Peak factor of 1.5x for equipment sizing"
      ],
      "confidence_level": "High"
    }
    ```
    
    **Frontend Integration:**
    Use this data in a "Validation" or "AI Insights" tab to show
    engineers the reasoning behind the proposal.
    """
    # Verify project access
    result = await db.execute(
        select(Project).where(
            Project.id == project_id,
            Project.user_id == current_user.id,
        )
    )
    project = result.scalar_one_or_none()
    
    if not project:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Project not found",
        )
    
    # Get proposal
    from app.models.proposal import Proposal
    result = await db.execute(
        select(Proposal).where(
            Proposal.id == proposal_id,
            Proposal.project_id == project_id,
        )
    )
    proposal = result.scalar_one_or_none()
    
    if not proposal:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Proposal not found",
        )
    
    # ‚úÖ Get AI metadata directly from PostgreSQL (single source of truth)
    ai_metadata = proposal.ai_metadata
    
    if not ai_metadata:
        logger.warning(f"‚ö†Ô∏è No AI metadata found for proposal {proposal_id}")
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="No AI metadata available for this proposal."
        )
    
    try:
        # Validate with Pydantic (catches corrupted data)
        validated_metadata = AIMetadataResponse(**ai_metadata)
        logger.info(
            f"‚úÖ Returning validated AI metadata",
            extra={
                "proposal_id": str(proposal_id),
                "confidence": validated_metadata.confidence_level,
                "proven_cases_count": len(validated_metadata.proven_cases),
                "model": validated_metadata.usage_stats.model_used
            }
        )
        return validated_metadata
    except Exception as e:
        logger.error(
            f"‚ùå Failed to validate AI metadata: {e}",
            extra={"proposal_id": str(proposal_id)},
            exc_info=True
        )
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            detail=f"AI metadata validation failed: {str(e)}"
        )
