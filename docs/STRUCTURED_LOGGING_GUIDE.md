# ðŸ“ GuÃ­a de Structured Logging con structlog

**Implementado**: Octubre 6, 2025  
**LibrerÃ­a**: structlog 24.4.0  
**Estado**: âœ… Activo en producciÃ³n

---

## ðŸŽ¯ Â¿Por QuÃ© Structured Logging?

### Problemas con logs tradicionales:
```python
# âŒ Log tradicional (difÃ­cil de buscar/analizar)
logger.info(f"Proposal generated for project {project_id} by user {user_id}")
logger.error(f"Error: {e}")
```

**Desventajas:**
- Imposible buscar por campos especÃ­ficos
- No se pueden generar mÃ©tricas automÃ¡ticas
- Formato inconsistente
- DifÃ­cil integraciÃ³n con herramientas de observability

### SoluciÃ³n con structured logging:
```python
# âœ… Structured log (contextual, searchable, mÃ©tricas automÃ¡ticas)
logger.info(
    "proposal_generated",
    proposal_id=str(proposal.id),
    project_id=str(project_id),
    user_id=str(user_id),
    duration_seconds=duration,
    tokens_used=tokens
)
```

**Ventajas:**
- âœ… BÃºsqueda exacta: `grep proposal_id=123 logs/`
- âœ… MÃ©tricas automÃ¡ticas por campo
- âœ… Formato JSON consistente
- âœ… IntegraciÃ³n directa con Datadog, Grafana, CloudWatch

---

## ðŸš€ ConfiguraciÃ³n Actual

### En `app/main.py`:

```python
import structlog

if settings.ENVIRONMENT == "production":
    # ProducciÃ³n: JSON output para agregaciÃ³n de logs
    processors = [
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer(),  # â† JSON
    ]
else:
    # Desarrollo: Colored output legible
    processors = [
        # ... mismos procesadores ...
        structlog.dev.ConsoleRenderer(),  # â† Coloreado
    ]

structlog.configure(
    processors=processors,
    wrapper_class=structlog.stdlib.BoundLogger,
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    cache_logger_on_first_use=True,
)
```

**Beneficio**: Logs legibles en desarrollo, JSON en producciÃ³n.

---

## ðŸ“– GuÃ­a de Uso

### 1. Importar en tu mÃ³dulo

```python
import structlog

logger = structlog.get_logger(__name__)
```

**NO uses**: `import logging` ni `logging.getLogger()`  
**USA**: `import structlog` y `structlog.get_logger()`

---

### 2. Logs de InformaciÃ³n (INFO)

**CuÃ¡ndo usar**: Operaciones exitosas, hitos importantes.

```python
# âœ… CORRECTO: Event name + contexto estructurado
logger.info(
    "proposal_generated",  # Event name (snake_case)
    proposal_id=str(proposal.id),
    project_id=str(project_id),
    user_id=str(user_id),
    proposal_type="Technical",
    duration_seconds=45.2,
    tokens_used=15000,
    cost_usd=0.05
)
```

**Salida en desarrollo:**
```
2025-10-06T10:30:45 [info] proposal_generated
    proposal_id=550e8400-e29b-41d4-a716-446655440000
    project_id=660e8400-e29b-41d4-a716-446655440001
    user_id=770e8400-e29b-41d4-a716-446655440002
    duration_seconds=45.2
```

**Salida en producciÃ³n (JSON):**
```json
{
  "event": "proposal_generated",
  "level": "info",
  "timestamp": "2025-10-06T10:30:45.123456Z",
  "logger": "app.services.proposal_service",
  "proposal_id": "550e8400-e29b-41d4-a716-446655440000",
  "project_id": "660e8400-e29b-41d4-a716-446655440001",
  "user_id": "770e8400-e29b-41d4-a716-446655440002",
  "duration_seconds": 45.2,
  "tokens_used": 15000,
  "cost_usd": 0.05
}
```

---

### 3. Logs de Advertencia (WARNING)

**CuÃ¡ndo usar**: Situaciones anÃ³malas pero recuperables.

```python
# âœ… CORRECTO
logger.warning(
    "using_legacy_relational_data",
    project_id=str(project.id),
    sections_count=5,
    source="relational",
    reason="no_jsonb_data_found"
)
```

**Ejemplo real del cÃ³digo:**
```python
if not jsonb_sections:
    logger.warning(
        "no_technical_data_found",
        project_id=str(project.id),
        source="none",
        action="returning_minimal_structure"
    )
```

---

### 4. Logs de Error (ERROR)

**CuÃ¡ndo usar**: Errores capturados que impiden completar la operaciÃ³n.

```python
# âœ… CORRECTO: Incluye exc_info=True para stack trace
try:
    result = await risky_operation()
except Exception as e:
    logger.error(
        "operation_failed",
        exc_info=True,  # â† Stack trace automÃ¡tico
        project_id=str(project_id),
        error_type=type(e).__name__,
        error_message=str(e),
        operation="risky_operation"
    )
    raise
```

**Ejemplo real del cÃ³digo:**
```python
except ProposalGenerationError as e:
    logger.error(
        "proposal_generation_failed",
        exc_info=True,
        project_id=str(project_id),
        job_id=job_id,
        error_type=type(e).__name__,
        error_message=str(e)
    )
```

**Beneficio de `exc_info=True`:**
- Captura automÃ¡ticamente el stack trace completo
- Lo serializa como JSON en producciÃ³n
- FÃ¡cil de buscar por tipo de error

---

### 5. Logs con MÃ©tricas de Performance

**PatrÃ³n comÃºn**: Medir duraciÃ³n de operaciones.

```python
import time

start_time = time.time()

# ... operaciÃ³n ...

logger.info(
    "operation_completed",
    operation="generate_proposal",
    duration_seconds=round(time.time() - start_time, 2),
    tokens_used=15000,
    cost_usd=0.05
)
```

**Ejemplo real del cÃ³digo:**
```python
start_time = time.time()
proposal_output, usage_stats = await generate_enhanced_proposal(...)
generation_duration = time.time() - start_time

logger.info(
    "ai_proposal_generated",
    project_id=str(project_id),
    job_id=job_id,
    duration_seconds=round(generation_duration, 2),
    tokens_used=usage_stats.get('total_tokens', 0),
    model=usage_stats.get('model_used', 'unknown'),
    cost_usd=usage_stats.get('cost_estimate', 0)
)
```

---

## ðŸ” BÃºsqueda y AnÃ¡lisis de Logs

### Buscar por campo especÃ­fico:

```bash
# Buscar todas las propuestas del proyecto X
grep "project_id=550e8400" logs/app.log

# Buscar errores de un tipo especÃ­fico
grep "error_type=ValidationError" logs/app.log

# Buscar operaciones lentas (>60 segundos)
grep -E "duration_seconds=[6-9][0-9]|duration_seconds=[0-9]{3}" logs/app.log
```

### En producciÃ³n (JSON):

```bash
# Con jq (parser JSON)
cat logs/app.log | jq 'select(.event == "proposal_generated")'
cat logs/app.log | jq 'select(.duration_seconds > 60)'
cat logs/app.log | jq 'select(.error_type == "OpenAIError")'
```

---

## ðŸ“Š MÃ©tricas AutomÃ¡ticas

Con logs estructurados, puedes generar mÃ©tricas fÃ¡cilmente:

### Contar propuestas por tipo:
```bash
grep "proposal_generated" logs/app.log | grep -o "proposal_type=[^,]*" | sort | uniq -c
```

### Calcular promedio de duraciÃ³n:
```bash
grep "proposal_generated" logs/app.log | \
  grep -o "duration_seconds=[0-9.]*" | \
  cut -d= -f2 | \
  awk '{sum+=$1; count++} END {print sum/count}'
```

### Total de tokens consumidos (costo):
```bash
grep "tokens_used" logs/app.log | \
  grep -o "tokens_used=[0-9]*" | \
  cut -d= -f2 | \
  awk '{sum+=$1} END {print sum}'
```

---

## ðŸŽ¨ Convenciones de Nombres

### Event Names (primer parÃ¡metro):
- **snake_case** siempre
- **Verbos en pasado** para acciones completadas: `proposal_generated`, `user_registered`
- **Verbos en presente** para estados: `loading_data`, `processing_request`

```python
# âœ… CORRECTO
logger.info("proposal_generated", ...)
logger.info("loading_technical_data", ...)
logger.error("validation_failed", ...)

# âŒ INCORRECTO
logger.info("ProposalGenerated", ...)  # No usar PascalCase
logger.info("generate_proposal", ...)  # Presente, no pasado
logger.info("Proposal generated", ...)  # Espacios, no snake_case
```

### Campos de contexto:
- **UUIDs**: Siempre convertir a string con `str(uuid)`
- **Duraciones**: Usar `duration_seconds` (float redondeado)
- **Timestamps**: Usar ISO 8601 con `.isoformat()`
- **Booleanos**: `has_*`, `is_*`, `should_*`

```python
# âœ… CORRECTO
logger.info(
    "data_loaded",
    project_id=str(project.id),  # UUID â†’ str
    duration_seconds=round(duration, 2),  # Float redondeado
    timestamp=datetime.utcnow().isoformat(),  # ISO 8601
    has_ai_metadata=True,  # Boolean explÃ­cito
    filled_fields=15,  # NÃºmeros sin unidad si es obvio
    completeness_percent=75.5  # Porcentajes con _percent
)
```

---

## ðŸ”§ IntegraciÃ³n con Observability Tools

### Datadog

```python
# Los logs JSON se envÃ­an automÃ¡ticamente a Datadog
# Buscar en Datadog con queries como:
@event:proposal_generated @duration_seconds:>60
@error_type:OpenAIError
@proposal_type:Technical
```

### Grafana + Loki

```promql
# Query en Loki
{job="h2o-backend"} | json | event="proposal_generated" | duration_seconds > 60
```

### CloudWatch Insights

```sql
fields @timestamp, proposal_id, duration_seconds
| filter event = "proposal_generated"
| stats avg(duration_seconds) by proposal_type
```

---

## ðŸ“‹ Checklist para Nuevos Logs

Antes de agregar un log, verifica:

- [ ] Â¿El event name es **snake_case**?
- [ ] Â¿Incluye **contexto suficiente** (IDs, duraciÃ³n, estado)?
- [ ] Â¿Los UUIDs estÃ¡n convertidos a **string**?
- [ ] Â¿Los errores incluyen **exc_info=True**?
- [ ] Â¿Es **INFO, WARNING o ERROR** apropiado?
- [ ] Â¿AyudarÃ¡ a **debuggear** problemas en producciÃ³n?

---

## ðŸŽ¯ Ejemplos Completos

### Ejemplo 1: OperaciÃ³n con duraciÃ³n

```python
import time
import structlog

logger = structlog.get_logger(__name__)

async def process_data(project_id: UUID, user_id: UUID):
    start_time = time.time()
    
    logger.info(
        "data_processing_started",
        project_id=str(project_id),
        user_id=str(user_id)
    )
    
    try:
        result = await heavy_operation()
        
        logger.info(
            "data_processing_completed",
            project_id=str(project_id),
            user_id=str(user_id),
            duration_seconds=round(time.time() - start_time, 2),
            records_processed=len(result)
        )
        return result
        
    except Exception as e:
        logger.error(
            "data_processing_failed",
            exc_info=True,
            project_id=str(project_id),
            user_id=str(user_id),
            error_type=type(e).__name__,
            error_message=str(e),
            duration_seconds=round(time.time() - start_time, 2)
        )
        raise
```

### Ejemplo 2: Log con mÃ©tricas de AI

```python
logger.info(
    "ai_request_completed",
    model="gpt-4o-mini",
    prompt_tokens=500,
    completion_tokens=1500,
    total_tokens=2000,
    cost_usd=0.02,
    duration_seconds=3.5,
    response_quality="high"
)
```

### Ejemplo 3: Log con decisiÃ³n del sistema

```python
if use_cache:
    logger.info(
        "cache_hit",
        cache_key=cache_key,
        ttl_remaining=300
    )
else:
    logger.info(
        "cache_miss",
        cache_key=cache_key,
        reason="expired"
    )
```

---

## ðŸš€ MigraciÃ³n de Logs Existentes

### Antes (logging tradicional):
```python
import logging
logger = logging.getLogger(__name__)

logger.info(f"âœ… Proposal {proposal.id} generated in {duration}s")
logger.error(f"Error: {e}")
```

### DespuÃ©s (structlog):
```python
import structlog
logger = structlog.get_logger(__name__)

logger.info(
    "proposal_generated",
    proposal_id=str(proposal.id),
    duration_seconds=duration
)
logger.error(
    "operation_failed",
    exc_info=True,
    error_type=type(e).__name__
)
```

---

## ðŸ“š Referencias

- [structlog Documentation](https://www.structlog.org/en/stable/)
- [JSON Logging Best Practices](https://betterstack.com/community/guides/logging/json-logging/)
- [Observability Best Practices 2025](https://www.datadoghq.com/blog/logging-best-practices/)

---

**Â¡Happy Logging! ðŸŽ‰**
